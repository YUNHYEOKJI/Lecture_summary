{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=navy> Lecture 4. Variable Selection and Shrinkage Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "data_path = \"../data/\"\n",
    "credit = pd.read_csv(data_path + \"Credit.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 4.1 최소제곱추정량(LSE)의 개선\n",
    "- RSS를 최소화 하는 $\\hat \\beta$를 찾는 LSE 외에 다른 추정 방법을 고려 \n",
    "\n",
    "### 4.1.1 왜 LSE 대신 다른 방법을 사용하려 하는가? \n",
    "__예측 정확도__\n",
    "\n",
    "- 반응변수와 설명변수들 사이의 실제 상관관계가 거의 선형적인 경우 LSE의 편향(bias)가 작음 \n",
    "- $n>>p$인 경우 LSE는 분산이 작아 좋은 성능 \n",
    "- $n$이 $p$보다 많이 크지 않다면\n",
    "    -  LSE의 변동성 큼\n",
    "    - 과적합으로 인해 미래의 관측치에 대한 예측력 저하 \n",
    "    \n",
    "__모델 해석력(model interpretability)__\n",
    "\n",
    "- 반응변수와 관련이 없는 설명변수가 모형에 포함되면 복잡도 증가 \n",
    "- 필요없는 변수를 제거하여 해석력을 증가 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1.2 Bias/variance tradeoff\n",
    "\n",
    "- 모델을 일반화 시킬 때 발생하는 error\n",
    "    - Bias: 모델에 대한 가정이 잘못되서 생기는 error \n",
    "    - Variance: Training data에 대해 지나치게 민감해서 발생되는 error\n",
    "\n",
    "\n",
    "\n",
    "<img src='http://drive.google.com/uc?export=view&id=1sau3vf5fueJ5bYdGf8o7FFFjz1o-vXzy' /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $J_{train}(\\theta)$: Train set을 사용한 모형의 loss function \n",
    "- $J_{test}(\\theta)$: Test set을 사용한 모형의 loss function \n",
    "    - Linear regression 의 경우 RSS($\\mathbf \\beta$)$=\\sum_{i} (y_i - \\hat y_i )^2$\n",
    "\n",
    "<img src='http://drive.google.com/uc?export=view&id=1Fz2iAraKz9wwEhhVJ3Yx3ONIuYl1qZHv' width=300 /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### 4.1.3 최소제곱추정량의 대안 \n",
    "- 부분집합 선택\n",
    "    - p개의 설명변수 중 반응변수와 관련이 있다고 생각되는 서브셋을 식별 후 최소제곱법으로 추정 \n",
    "    - Backward selection, forward selection, mixed selection, best subset selection\n",
    "\n",
    "- 수축(shrinkage)\n",
    "    - p개의 설명변수를 모두 포함하는 모형을 추정\n",
    "    - 회귀계수를 LSE보다 작은 값으로 수축 \n",
    "    - 분산을 줄이는 효과 \n",
    "\n",
    "- 차원축소(Dimension reduction)\n",
    "    - p개의 설명변수를 저차원의 공간으로 projection \n",
    "    - 주성분분석(principal component analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2 변수선택 방법\n",
    "\n",
    "- 어느 설명변수가 반응변수와 상관성이 있는가? \n",
    "    - 전진선택 (forward selection)\n",
    "        - 절편만 포함한 null model에서 시작\n",
    "        - p 개의 단순선형회귀 적합. 가장 낮은 RSS가 발생되는 변수를 추가 \n",
    "        - 새로운 2변수 모델에 대해 가장 낮은 RSS가 발생되는 변수 추가 \n",
    "        - stopping rule을 만족할 때 까지 반복 \n",
    "    - 후진선택 (backward elimination)\n",
    "        - 모델의 모든 변수를 가지고 시작\n",
    "        - 제외했을 때 가장 RSS가 작은 변수 제외\n",
    "        - 새로운 (p-1)-변수 모델을 적합하고 RSS가 가장 작은 변수 제외\n",
    "        - stopping rule을 만족할 때 까지 계속 \n",
    "    - 혼합선택 (mixed selection)  \n",
    "        - 변수가 없는 모델에서 시작하여 하나씩 추가\n",
    "        - 새로운 설명변수가 추가됨에 따라 기존의 변수들의 유의하지 않을 수 있음 \n",
    "        - 매 단계에서 기존 변수가 제거되었을 때와 비교하여 best model 선택 \n",
    "    - 최상의 부분집합 선택 (Best subset selection)\n",
    "        - 가능한 모든 설명변수 조합의 모형들 중 최적의 모형 선택 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### 최상의 부분집합 선택 \n",
    "- 포함하는 설명변수들이 서로 다른 많은 수의 모델을 시험하여 최상의 모델 선택 (p=2인 경우 총 4개의 모델)\n",
    "- 최고의 모델을 선택하는 기준? (총 p개 중 d개의 설명변수가 포함된 모델)\n",
    "\n",
    "    $$ AIC= \\frac 1 {n\\hat \\sigma^2 } (RSS + 2d\\hat \\sigma^2)$$\n",
    "    $$ BIC=\\frac 1 n (RSS+ \\log(n) d\\hat \\sigma^2 ) $$\n",
    "    $$ R_a^2 = 1-(1-R^2) \\frac{n-1}{n-p-1} $$\n",
    "\n",
    "- AIC, BIC\n",
    "    - 작은 오차를 가지는 모델들이 작은 값을 가지는 경향\n",
    "    - 변수의 개수에 대한 패널티 부여\n",
    "    - 각 기준으로 가장 낮은 값을 가지는 모형 선택\n",
    "    - BIC가 더 작은 크기의 모델이 선택되는 경향\n",
    "-  Adjusted $R^2$\n",
    "    - 클 수록 오차가 작은 모델\n",
    "    - 올바른 변수들이 모두 모델에 포함되고 나면 불필요한 변수의 추가로 얻는 RSS 감소는 미세한 반면 변수 개수 추가에 의한 패널티 값이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "y, X = patsy.dmatrices('Balance~'+\"+\".join(credit.columns[:-1]), data = credit, return_type='dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Gender[T.Female]</th>\n",
       "      <th>Student[T.Yes]</th>\n",
       "      <th>Married[T.Yes]</th>\n",
       "      <th>Ethnicity[T.Asian]</th>\n",
       "      <th>Ethnicity[T.Caucasian]</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.891</td>\n",
       "      <td>3606.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.025</td>\n",
       "      <td>6645.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.593</td>\n",
       "      <td>7075.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.924</td>\n",
       "      <td>9504.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.882</td>\n",
       "      <td>4897.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  Gender[T.Female]  Student[T.Yes]  Married[T.Yes]  \\\n",
       "1        1.0               0.0             0.0             1.0   \n",
       "2        1.0               1.0             1.0             1.0   \n",
       "3        1.0               0.0             0.0             0.0   \n",
       "4        1.0               1.0             0.0             0.0   \n",
       "5        1.0               0.0             0.0             1.0   \n",
       "\n",
       "   Ethnicity[T.Asian]  Ethnicity[T.Caucasian]   Income   Limit  Rating  Cards  \\\n",
       "1                 0.0                     1.0   14.891  3606.0   283.0    2.0   \n",
       "2                 1.0                     0.0  106.025  6645.0   483.0    3.0   \n",
       "3                 1.0                     0.0  104.593  7075.0   514.0    4.0   \n",
       "4                 1.0                     0.0  148.924  9504.0   681.0    3.0   \n",
       "5                 0.0                     1.0   55.882  4897.0   357.0    2.0   \n",
       "\n",
       "    Age  Education  \n",
       "1  34.0       11.0  \n",
       "2  82.0       15.0  \n",
       "3  71.0       11.0  \n",
       "4  36.0       11.0  \n",
       "5  68.0       16.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Balance\n",
       "1    333.0\n",
       "2    903.0\n",
       "3    580.0\n",
       "4    964.0\n",
       "5    331.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Best subset selection을 위한 코드 \n",
    "# Source: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab8-py.html\n",
    "# Modified by Yeojin Chung\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    X_model = X[list(('Intercept',)+feature_set)]\n",
    "    model = sm.OLS(y, X_model)\n",
    "    regr = model.fit()\n",
    "    RSS = (regr.resid ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS, \"AIC\": regr.aic, \n",
    "            \"BIC\": regr.bic, \"adj_r2\": regr.rsquared_adj,\n",
    "           \"r2\":regr.rsquared }\n",
    "\n",
    "def getBest(k, best = \"AIC\"):\n",
    "    \n",
    "    tic = time.time()   \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns[1:], k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    if best==\"adj_r2\" or best==\"r2\":\n",
    "        best_model = models.loc[models[best].argmax()]\n",
    "    else: \n",
    "        best_model = models.loc[models[best].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11 models on 1 predictors in 0.018939971923828125 seconds.\n",
      "Processed 55 models on 2 predictors in 0.06383681297302246 seconds.\n",
      "Processed 165 models on 3 predictors in 0.2652902603149414 seconds.\n",
      "Processed 330 models on 4 predictors in 0.47672414779663086 seconds.\n",
      "Processed 462 models on 5 predictors in 0.5305817127227783 seconds.\n",
      "Processed 462 models on 6 predictors in 0.5216035842895508 seconds.\n",
      "Processed 330 models on 7 predictors in 0.36805224418640137 seconds.\n",
      "Processed 165 models on 8 predictors in 0.19947195053100586 seconds.\n",
      "Processed 55 models on 9 predictors in 0.0638277530670166 seconds.\n",
      "Processed 11 models on 10 predictors in 0.0139617919921875 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_best = pd.DataFrame(columns=[\"model\", \"RSS\",\"AIC\",\"BIC\",\"adj_r2\", \"r2\"])\n",
    "\n",
    "for i in range(1,X.shape[1]-1):\n",
    "    models_best.loc[i] = getBest(i, best = \"AIC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RSS</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>adj_r2</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>2.143512e+07</td>\n",
       "      <td>5494.781548</td>\n",
       "      <td>5502.764477</td>\n",
       "      <td>0.745210</td>\n",
       "      <td>0.745848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.053254e+07</td>\n",
       "      <td>5212.557085</td>\n",
       "      <td>5224.531479</td>\n",
       "      <td>0.874489</td>\n",
       "      <td>0.875118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>4.227219e+06</td>\n",
       "      <td>4849.386992</td>\n",
       "      <td>4865.352851</td>\n",
       "      <td>0.949499</td>\n",
       "      <td>0.949879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.915058e+06</td>\n",
       "      <td>4820.701337</td>\n",
       "      <td>4840.658660</td>\n",
       "      <td>0.953110</td>\n",
       "      <td>0.953580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.866091e+06</td>\n",
       "      <td>4817.666820</td>\n",
       "      <td>4841.615607</td>\n",
       "      <td>0.953579</td>\n",
       "      <td>0.954161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.821620e+06</td>\n",
       "      <td>4815.038963</td>\n",
       "      <td>4842.979215</td>\n",
       "      <td>0.953996</td>\n",
       "      <td>0.954688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.810759e+06</td>\n",
       "      <td>4815.900560</td>\n",
       "      <td>4847.832276</td>\n",
       "      <td>0.954010</td>\n",
       "      <td>0.954817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.804746e+06</td>\n",
       "      <td>4817.268900</td>\n",
       "      <td>4853.192081</td>\n",
       "      <td>0.953965</td>\n",
       "      <td>0.954888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.798367e+06</td>\n",
       "      <td>4818.597738</td>\n",
       "      <td>4858.512384</td>\n",
       "      <td>0.953924</td>\n",
       "      <td>0.954964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>3.791345e+06</td>\n",
       "      <td>4819.857603</td>\n",
       "      <td>4863.763713</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>0.955047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model           RSS  \\\n",
       "1   <statsmodels.regression.linear_model.Regressio...  2.143512e+07   \n",
       "2   <statsmodels.regression.linear_model.Regressio...  1.053254e+07   \n",
       "3   <statsmodels.regression.linear_model.Regressio...  4.227219e+06   \n",
       "4   <statsmodels.regression.linear_model.Regressio...  3.915058e+06   \n",
       "5   <statsmodels.regression.linear_model.Regressio...  3.866091e+06   \n",
       "6   <statsmodels.regression.linear_model.Regressio...  3.821620e+06   \n",
       "7   <statsmodels.regression.linear_model.Regressio...  3.810759e+06   \n",
       "8   <statsmodels.regression.linear_model.Regressio...  3.804746e+06   \n",
       "9   <statsmodels.regression.linear_model.Regressio...  3.798367e+06   \n",
       "10  <statsmodels.regression.linear_model.Regressio...  3.791345e+06   \n",
       "\n",
       "            AIC          BIC    adj_r2        r2  \n",
       "1   5494.781548  5502.764477  0.745210  0.745848  \n",
       "2   5212.557085  5224.531479  0.874489  0.875118  \n",
       "3   4849.386992  4865.352851  0.949499  0.949879  \n",
       "4   4820.701337  4840.658660  0.953110  0.953580  \n",
       "5   4817.666820  4841.615607  0.953579  0.954161  \n",
       "6   4815.038963  4842.979215  0.953996  0.954688  \n",
       "7   4815.900560  4847.832276  0.954010  0.954817  \n",
       "8   4817.268900  4853.192081  0.953965  0.954888  \n",
       "9   4818.597738  4858.512384  0.953924  0.954964  \n",
       "10  4819.857603  4863.763713  0.953891  0.955047  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(models_best['adj_r2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_final = models_best.iloc[models_best['adj_r2'].argmax(),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Balance</td>     <th>  R-squared:         </th> <td>   0.955</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.954</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1183.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 13 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>3.50e-259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:51:52</td>     <th>  Log-Likelihood:    </th> <td> -2400.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   4816.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   392</td>      <th>  BIC:               </th> <td>   4848.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td> -488.6159</td> <td>   25.289</td> <td>  -19.321</td> <td> 0.000</td> <td> -538.335</td> <td> -438.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender[T.Female]</th> <td>  -10.4532</td> <td>    9.890</td> <td>   -1.057</td> <td> 0.291</td> <td>  -29.896</td> <td>    8.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Student[T.Yes]</th>   <td>  426.5813</td> <td>   16.533</td> <td>   25.802</td> <td> 0.000</td> <td>  394.077</td> <td>  459.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>           <td>   -7.8036</td> <td>    0.234</td> <td>  -33.417</td> <td> 0.000</td> <td>   -8.263</td> <td>   -7.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Limit</th>            <td>    0.1936</td> <td>    0.032</td> <td>    5.980</td> <td> 0.000</td> <td>    0.130</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rating</th>           <td>    1.0940</td> <td>    0.485</td> <td>    2.257</td> <td> 0.025</td> <td>    0.141</td> <td>    2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cards</th>            <td>   18.1092</td> <td>    4.319</td> <td>    4.193</td> <td> 0.000</td> <td>    9.618</td> <td>   26.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>              <td>   -0.6207</td> <td>    0.292</td> <td>   -2.127</td> <td> 0.034</td> <td>   -1.194</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>34.049</td> <th>  Durbin-Watson:     </th> <td>   1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  40.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.773</td> <th>  Prob(JB):          </th> <td>1.53e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.211</td> <th>  Cond. No.          </th> <td>2.72e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.72e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Balance   R-squared:                       0.955\n",
       "Model:                            OLS   Adj. R-squared:                  0.954\n",
       "Method:                 Least Squares   F-statistic:                     1183.\n",
       "Date:                Sun, 13 Feb 2022   Prob (F-statistic):          3.50e-259\n",
       "Time:                        16:51:52   Log-Likelihood:                -2400.0\n",
       "No. Observations:                 400   AIC:                             4816.\n",
       "Df Residuals:                     392   BIC:                             4848.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept         -488.6159     25.289    -19.321      0.000    -538.335    -438.897\n",
       "Gender[T.Female]   -10.4532      9.890     -1.057      0.291     -29.896       8.990\n",
       "Student[T.Yes]     426.5813     16.533     25.802      0.000     394.077     459.085\n",
       "Income              -7.8036      0.234    -33.417      0.000      -8.263      -7.345\n",
       "Limit                0.1936      0.032      5.980      0.000       0.130       0.257\n",
       "Rating               1.0940      0.485      2.257      0.025       0.141       2.047\n",
       "Cards               18.1092      4.319      4.193      0.000       9.618      26.601\n",
       "Age                 -0.6207      0.292     -2.127      0.034      -1.194      -0.047\n",
       "==============================================================================\n",
       "Omnibus:                       34.049   Durbin-Watson:                   1.955\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.600\n",
       "Skew:                           0.773   Prob(JB):                     1.53e-09\n",
       "Kurtosis:                       3.211   Cond. No.                     2.72e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.72e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.3  Shrinkage method\n",
    "### Ridge Regression\n",
    "\n",
    "$$RSS + \\lambda \\sum_{j=1}^p \\beta_j^2 $$\n",
    "\n",
    "- $\\lambda \\geq 0$: tuning parameter \n",
    "    - 여러 $\\lambda$을 시도해 보고 좋은 값을 선택 \n",
    "- RSS+ L2 penalty의 형태 \n",
    "- $\\beta_j$의 추정치를 0과 가깝게 수축하는 효과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = ridge_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -1.01531108e+01,  4.13899860e+02,\n",
       "        -9.12155389e+00,  1.67728726e+01,  9.66826039e+00,\n",
       "        -7.79613765e+00,  1.88633083e-01,  1.16935286e+00,\n",
       "         1.74952276e+01, -6.22845855e-01, -1.00749787e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lasso Regression\n",
    "- Ridge regression은 $\\beta_j$값이 0을 향해 수축하지만 정확하게 0을 만들지는 않음 \n",
    "\n",
    "$$RSS + \\lambda \\sum_{j=1}^p |\\beta_j| $$\n",
    "\n",
    "- L1 penalty를 사용 \n",
    "- $\\lambda$가 충분히 클 경우 계수 추정치의 일부가 정확히 0이 되게 함 \n",
    "- 변수선택의 효과 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='http://drive.google.com/uc?export=view&id=1TVY99Zg9H6bRacibI_RJxuZZqPX3SO35' /><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ridge는 $\\beta_j$를 전체적으로 축소시키는 효과\n",
    "- Lasso는 덜 중요한 변수에 대해 $\\beta_j=0$으로 만드는 효과\n",
    "    - 자동적인 feature selection 과정 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapse": false,
    "lines_to_next_cell": 2,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zyunhyeok\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1893812.8720691514, tolerance: 8433.991191\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.01)\n",
    "lasso_reg.fit(X, y)\n",
    "\n",
    "y_pred = lasso_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.06082218e+01,  4.25689009e+02, -8.45041224e+00,\n",
       "        1.66497454e+01,  9.99657462e+00, -7.80320873e+00,  1.91959216e-01,\n",
       "        1.12083024e+00,  1.77952880e+01, -6.13858939e-01, -1.10161563e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.coef_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,collapse,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python3.8_DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
