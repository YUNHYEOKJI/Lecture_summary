{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 13개의 설명변수를 모두 사용하여 medev를 설명하는 회귀모형을 적합하고 각 설명변수의 VIF 값을 계산하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "data_path = \"../data/\"\n",
    "boston = pd.read_csv(data_path + \"Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'medv~'+'+'.join(boston.columns[:-1]);formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>medv</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 26 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:13:22</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crim</th>      <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zn</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indus</th>     <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chas</th>      <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rm</th>        <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tax</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   medv   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Mon, 26 Apr 2021   Prob (F-statistic):          6.72e-135\n",
       "Time:                        16:13:22   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "crim          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "zn             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "indus          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "chas           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "nox          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "rm             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "age            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "dis           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "rad            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "tax           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "ptratio       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "black          0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "lstat         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.ols(formula, boston).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF of Intercept : 585.2652379423121\n",
      "VIF of crim : 1.7921915474332413\n",
      "VIF of zn : 2.298758178749441\n",
      "VIF of indus : 3.9915964183460333\n",
      "VIF of chas : 1.0739953275537883\n",
      "VIF of nox : 4.393719847577495\n",
      "VIF of rm : 1.9337444357832558\n",
      "VIF of age : 3.1008255128153364\n",
      "VIF of dis : 3.9559449063727263\n",
      "VIF of rad : 7.484496335274478\n",
      "VIF of tax : 9.00855394759707\n",
      "VIF of ptratio : 1.7990840492488978\n",
      "VIF of black : 1.3485210764063755\n",
      "VIF of lstat : 2.9414910780919366\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(formula, boston).fit()\n",
    "import patsy\n",
    "y, X = patsy.dmatrices(formula, boston, return_type='matrix')\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "for i, x in enumerate(X.design_info.column_names):\n",
    "    print( 'VIF of', x, ':', variance_inflation_factor(X, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. All subset regression을 통해 변수선택을 하시오. AIC, BIC, adjusted R-square를 사용할 때 각 기준에 따라 최적의 모형이 달라지는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "y, X = patsy.dmatrices(formula, data = boston, return_type='dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    X_model = X[list(('Intercept',)+feature_set)]\n",
    "    model = sm.OLS(y, X_model)\n",
    "    regr = model.fit()\n",
    "    RSS = (regr.resid ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS, \"AIC\": regr.aic, \n",
    "            \"BIC\": regr.bic, \"adj_r2\": regr.rsquared_adj,\n",
    "           \"r2\":regr.rsquared }\n",
    "\n",
    "def getBest(k, best = \"AIC\"):\n",
    "    \n",
    "    tic = time.time()   \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns[1:], k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    if best==\"adj_r2\" or best==\"r2\":\n",
    "        best_model = models.loc[models[best].argmax()]\n",
    "    else: \n",
    "        best_model = models.loc[models[best].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13 models on 1 predictors in 0.03712344169616699 seconds.\n",
      "Processed 78 models on 2 predictors in 0.08477330207824707 seconds.\n",
      "Processed 286 models on 3 predictors in 0.3061814308166504 seconds.\n",
      "Processed 715 models on 4 predictors in 0.8088865280151367 seconds.\n",
      "Processed 1287 models on 5 predictors in 1.4840373992919922 seconds.\n",
      "Processed 1716 models on 6 predictors in 2.109361171722412 seconds.\n",
      "Processed 1716 models on 7 predictors in 2.1422715187072754 seconds.\n",
      "Processed 1287 models on 8 predictors in 1.6255042552947998 seconds.\n",
      "Processed 715 models on 9 predictors in 0.99041748046875 seconds.\n",
      "Processed 286 models on 10 predictors in 0.35300540924072266 seconds.\n",
      "Processed 78 models on 11 predictors in 0.10177803039550781 seconds.\n",
      "Processed 13 models on 12 predictors in 0.01795363426208496 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_best = pd.DataFrame(columns=[\"model\", \"RSS\",\"AIC\",\"BIC\",\"adj_r2\", \"r2\"])\n",
    "\n",
    "for i in range(1,X.shape[1]-1):\n",
    "    models_best.loc[i] = getBest(i, best = \"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RSS</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>adj_r2</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>19472.381418</td>\n",
       "      <td>3286.974957</td>\n",
       "      <td>3295.428030</td>\n",
       "      <td>0.543242</td>\n",
       "      <td>0.544146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>15439.309201</td>\n",
       "      <td>3171.542314</td>\n",
       "      <td>3184.221924</td>\n",
       "      <td>0.637124</td>\n",
       "      <td>0.638562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>13727.985314</td>\n",
       "      <td>3114.097267</td>\n",
       "      <td>3131.003414</td>\n",
       "      <td>0.676704</td>\n",
       "      <td>0.678624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>13228.907703</td>\n",
       "      <td>3097.359045</td>\n",
       "      <td>3118.491728</td>\n",
       "      <td>0.687835</td>\n",
       "      <td>0.690308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>12469.344151</td>\n",
       "      <td>3069.438633</td>\n",
       "      <td>3094.797853</td>\n",
       "      <td>0.705170</td>\n",
       "      <td>0.708089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>12141.072736</td>\n",
       "      <td>3057.939050</td>\n",
       "      <td>3087.524806</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.715774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11868.235607</td>\n",
       "      <td>3048.438383</td>\n",
       "      <td>3082.250676</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.722161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11678.299470</td>\n",
       "      <td>3042.274993</td>\n",
       "      <td>3080.313823</td>\n",
       "      <td>0.722207</td>\n",
       "      <td>0.726608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11526.122446</td>\n",
       "      <td>3037.638096</td>\n",
       "      <td>3079.903463</td>\n",
       "      <td>0.725274</td>\n",
       "      <td>0.730170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11308.577606</td>\n",
       "      <td>3029.996540</td>\n",
       "      <td>3076.488444</td>\n",
       "      <td>0.729915</td>\n",
       "      <td>0.735263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11081.363952</td>\n",
       "      <td>3021.726388</td>\n",
       "      <td>3072.444828</td>\n",
       "      <td>0.734806</td>\n",
       "      <td>0.740582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>11078.846412</td>\n",
       "      <td>3023.611418</td>\n",
       "      <td>3078.556395</td>\n",
       "      <td>0.734328</td>\n",
       "      <td>0.740641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model           RSS  \\\n",
       "1   <statsmodels.regression.linear_model.Regressio...  19472.381418   \n",
       "2   <statsmodels.regression.linear_model.Regressio...  15439.309201   \n",
       "3   <statsmodels.regression.linear_model.Regressio...  13727.985314   \n",
       "4   <statsmodels.regression.linear_model.Regressio...  13228.907703   \n",
       "5   <statsmodels.regression.linear_model.Regressio...  12469.344151   \n",
       "6   <statsmodels.regression.linear_model.Regressio...  12141.072736   \n",
       "7   <statsmodels.regression.linear_model.Regressio...  11868.235607   \n",
       "8   <statsmodels.regression.linear_model.Regressio...  11678.299470   \n",
       "9   <statsmodels.regression.linear_model.Regressio...  11526.122446   \n",
       "10  <statsmodels.regression.linear_model.Regressio...  11308.577606   \n",
       "11  <statsmodels.regression.linear_model.Regressio...  11081.363952   \n",
       "12  <statsmodels.regression.linear_model.Regressio...  11078.846412   \n",
       "\n",
       "            AIC          BIC    adj_r2        r2  \n",
       "1   3286.974957  3295.428030  0.543242  0.544146  \n",
       "2   3171.542314  3184.221924  0.637124  0.638562  \n",
       "3   3114.097267  3131.003414  0.676704  0.678624  \n",
       "4   3097.359045  3118.491728  0.687835  0.690308  \n",
       "5   3069.438633  3094.797853  0.705170  0.708089  \n",
       "6   3057.939050  3087.524806  0.712357  0.715774  \n",
       "7   3048.438383  3082.250676  0.718256  0.722161  \n",
       "8   3042.274993  3080.313823  0.722207  0.726608  \n",
       "9   3037.638096  3079.903463  0.725274  0.730170  \n",
       "10  3029.996540  3076.488444  0.729915  0.735263  \n",
       "11  3021.726388  3072.444828  0.734806  0.740582  \n",
       "12  3023.611418  3078.556395  0.734328  0.740641  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best['AIC'].argmin() # 인덱스가 10번째이므로 값은 11번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best['BIC'].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best['adj_r2'].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 위의 2번에서 선택된 최적의 모형들 중 가장 변수의 개수가 적은 모형을 최종모형으로 선택하여 회귀적합 결과와 VIF값을 프린트 하시오. Full model에 비해 VIF 값이 어떻게 변화했는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>medv</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.735</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   128.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 26 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>5.54e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:20:18</td>     <th>  Log-Likelihood:    </th> <td> -1498.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3022.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   3072.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.3411</td> <td>    5.067</td> <td>    7.171</td> <td> 0.000</td> <td>   26.385</td> <td>   46.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crim</th>      <td>   -0.1084</td> <td>    0.033</td> <td>   -3.307</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zn</th>        <td>    0.0458</td> <td>    0.014</td> <td>    3.390</td> <td> 0.001</td> <td>    0.019</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chas</th>      <td>    2.7187</td> <td>    0.854</td> <td>    3.183</td> <td> 0.002</td> <td>    1.040</td> <td>    4.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>  -17.3760</td> <td>    3.535</td> <td>   -4.915</td> <td> 0.000</td> <td>  -24.322</td> <td>  -10.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rm</th>        <td>    3.8016</td> <td>    0.406</td> <td>    9.356</td> <td> 0.000</td> <td>    3.003</td> <td>    4.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -1.4927</td> <td>    0.186</td> <td>   -8.037</td> <td> 0.000</td> <td>   -1.858</td> <td>   -1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.2996</td> <td>    0.063</td> <td>    4.726</td> <td> 0.000</td> <td>    0.175</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tax</th>       <td>   -0.0118</td> <td>    0.003</td> <td>   -3.493</td> <td> 0.001</td> <td>   -0.018</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>   -0.9465</td> <td>    0.129</td> <td>   -7.334</td> <td> 0.000</td> <td>   -1.200</td> <td>   -0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>    0.0093</td> <td>    0.003</td> <td>    3.475</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>   -0.5226</td> <td>    0.047</td> <td>  -11.019</td> <td> 0.000</td> <td>   -0.616</td> <td>   -0.429</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.430</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 787.785</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.523</td>  <th>  Prob(JB):          </th> <td>8.60e-172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.300</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   medv   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.735\n",
       "Method:                 Least Squares   F-statistic:                     128.2\n",
       "Date:                Mon, 26 Apr 2021   Prob (F-statistic):          5.54e-137\n",
       "Time:                        16:20:18   Log-Likelihood:                -1498.9\n",
       "No. Observations:                 506   AIC:                             3022.\n",
       "Df Residuals:                     494   BIC:                             3072.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.3411      5.067      7.171      0.000      26.385      46.298\n",
       "crim          -0.1084      0.033     -3.307      0.001      -0.173      -0.044\n",
       "zn             0.0458      0.014      3.390      0.001       0.019       0.072\n",
       "chas           2.7187      0.854      3.183      0.002       1.040       4.397\n",
       "nox          -17.3760      3.535     -4.915      0.000     -24.322     -10.430\n",
       "rm             3.8016      0.406      9.356      0.000       3.003       4.600\n",
       "dis           -1.4927      0.186     -8.037      0.000      -1.858      -1.128\n",
       "rad            0.2996      0.063      4.726      0.000       0.175       0.424\n",
       "tax           -0.0118      0.003     -3.493      0.001      -0.018      -0.005\n",
       "ptratio       -0.9465      0.129     -7.334      0.000      -1.200      -0.693\n",
       "black          0.0093      0.003      3.475      0.001       0.004       0.015\n",
       "lstat         -0.5226      0.047    -11.019      0.000      -0.616      -0.429\n",
       "==============================================================================\n",
       "Omnibus:                      178.430   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              787.785\n",
       "Skew:                           1.523   Prob(JB):                    8.60e-172\n",
       "Kurtosis:                       8.300   Cond. No.                     1.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = models_best.iloc[models_best['BIC'].argmin(),0]\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 11개의 설명변수, 몇개를 제외하니 계수들이 전부 유의해졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = model_final.model.exog # 설명변수를 모아놓은 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- patsy를 하지말고, 모형을 fullmodel을 fitting해서 이 값을 가져오는 것도 괜찮음 VIF 계산시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF of Intercept : 579.2558454136407\n",
      "VIF of crim : 1.7897041598301724\n",
      "VIF of zn : 2.2392286709170572\n",
      "VIF of chas : 1.0598192219819342\n",
      "VIF of nox : 3.7780109907146673\n",
      "VIF of rm : 1.834806373495738\n",
      "VIF of dis : 3.4434203360878866\n",
      "VIF of rad : 6.861126314588104\n",
      "VIF of tax : 7.272386358049807\n",
      "VIF of ptratio : 1.7576814966096734\n",
      "VIF of black : 1.3415587496473569\n",
      "VIF of lstat : 2.5819842679030978\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "for i, x in enumerate(model_final.model.exog_names):\n",
    "    print( 'VIF of', x, ':', variance_inflation_factor(X_final, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 9보다는 줄어들었기 때문에 이전보다는 다중공산성이 완화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
