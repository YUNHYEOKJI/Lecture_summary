{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "threatened-hobby",
   "metadata": {},
   "source": [
    "# gensim을 이용한 FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-conducting",
   "metadata": {},
   "source": [
    "### 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-secretary",
   "metadata": {},
   "source": [
    "https://github.com/e9t/nsmc/raw/master/ratings_train.txt 를 다운로드 받아 저장 후 연다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "awful-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get('https://github.com/e9t/nsmc/raw/master/ratings_train.txt')\n",
    "\n",
    "with open('../data/ratings_train.txt', 'wb') as f:\n",
    "    f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "temporal-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nsmc = pd.read_csv('../data/ratings_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupied-positive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-person",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elementary-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documented-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hangul(text):\n",
    "    return re.findall(r'[ㄱ-ㅎ가-힣]+', text) # 한글자이상의 한글을 모두 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developing-metro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '더빙', '진짜', '짜증나네요', '목소리']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_hangul(nsmc.loc[0,'document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "harmful-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149995 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[149995 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc[nsmc['document'].notnull()] # 5개의 비어있는 행을 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "otherwise-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nsmc[nsmc['document'].notnull()]['document'].map(find_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "killing-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '더빙', '진짜', '짜증나네요', '목소리']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-report",
   "metadata": {},
   "source": [
    "파일로 저장하는 방법도 있다. 먼저, 한글이 아닌 글자를 지우고 공백을 하나로 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naked-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_hangul(text):\n",
    "    return ' '.join(find_hangul(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "green-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 더빙 진짜 짜증나네요 목소리'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_hangul(nsmc.loc[0,'document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "medieval-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = nsmc[nsmc['document'].notnull()]['document'].map(only_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spoken-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 더빙 진짜 짜증나네요 목소리'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "satellite-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/nsmc.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-national",
   "metadata": {},
   "source": [
    "### FastText 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heated-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fitting-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-stevens",
   "metadata": {},
   "source": [
    "FastText 모형을 만든다. 설정값에는 다음과 같은 것들이 있다.\n",
    "\n",
    "- size: 임베딩의 크기 (기본값 100)\n",
    "- sg: 0이면 CBOW(기본값), 1이면 Skip-gram\n",
    "- alpha: 학습률 (기본값 0.025)\n",
    "- min_alpha: 최소 학습률. FastText는 학습과정에서 학습률을 이 수준까지 점점 낮춘다. (기본값 0.0001)\n",
    "- window: 문장 내에서 주변 단어와 대상 단어의 최대 거리(기본값 5) 좌우로 몇개의 단어까지\n",
    "- min_count: 임베딩을 학습할 단어의 최소 출현 빈도 (기본값 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-auckland",
   "metadata": {},
   "source": [
    "Word2Vec도 사용방법은 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "needed-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=16) # 단어하나마다 16차원으로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-plymouth",
   "metadata": {},
   "source": [
    "어휘를 파악한다. 파일로 저장한 경우에는 sentence=data 대신에 corpus_file='nsmc.txt'라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quarterly-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sentences=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cognitive-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build_vocab(corpus_file='nsmc.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-viking",
   "metadata": {},
   "source": [
    "모형을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minus-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    sentences=data,\n",
    "    epochs=5,\n",
    "    total_examples=model.corpus_count,\n",
    "    total_words=model.corpus_total_words\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-effects",
   "metadata": {},
   "source": [
    "### 저장과 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-elimination",
   "metadata": {},
   "source": [
    "저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "headed-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../data/nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-opening",
   "metadata": {},
   "source": [
    "불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "practical-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load('../data/nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-danish",
   "metadata": {},
   "source": [
    "# FastText 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-midwest",
   "metadata": {},
   "source": [
    "### 모형 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dying-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "model = FastText.load('../data/nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-nation",
   "metadata": {},
   "source": [
    "### 단어 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-cancer",
   "metadata": {},
   "source": [
    "'히어로'는 단어 임베딩이 학습되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "manual-pendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'히어로' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "indirect-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07591183,  0.48751894,  0.45523566,  0.7433716 , -0.52968186,\n",
       "       -0.14514065, -0.7991363 ,  0.2994704 ,  0.23659381,  0.3168685 ,\n",
       "       -0.7486586 , -0.03397258, -0.21045317, -0.2904963 ,  0.640995  ,\n",
       "       -0.73162127], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['히어로']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-guidance",
   "metadata": {},
   "source": [
    "'슈퍼히어로'는 단어 임베딩이 없지만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exterior-gilbert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'슈퍼히어로' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-shareware",
   "metadata": {},
   "source": [
    "준단어 토큰의 임베딩을 더해서 임베딩을 계산해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "civil-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05226331,  0.25863388,  0.22525036,  0.27956298, -0.21986212,\n",
       "       -0.07017983, -0.2935896 ,  0.08455249,  0.1033233 ,  0.06964119,\n",
       "       -0.33938393, -0.01331062, -0.08984356, -0.09376252,  0.27367273,\n",
       "       -0.2665792 ], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['슈퍼히어로']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-magnet",
   "metadata": {},
   "source": [
    "### 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "light-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-sherman",
   "metadata": {},
   "source": [
    "'히어로'와 '슈퍼히어로'의 유사도는 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "medium-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98800856"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('슈퍼히어로', '히어로')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-pilot",
   "metadata": {},
   "source": [
    "'히어로'와 '평론가'의 유사도는 상대적으로 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "leading-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68076"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('히어로', '평론가')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-passport",
   "metadata": {},
   "source": [
    "'평론가'와 비슷한 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "concrete-variance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('점이상은', 0.9908885955810547),\n",
       " ('평론가들', 0.9907047748565674),\n",
       " ('점이라', 0.9893724322319031),\n",
       " ('평론', 0.9891233444213867),\n",
       " ('점이야', 0.9885176420211792),\n",
       " ('점대면', 0.9881371855735779),\n",
       " ('점대라', 0.988065779209137),\n",
       " ('점이라니', 0.9879131317138672),\n",
       " ('조정', 0.9878653883934021),\n",
       " ('점대지', 0.9877920150756836)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('평론가')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-blast",
   "metadata": {},
   "source": [
    "# FastText를 이용한 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-assault",
   "metadata": {},
   "source": [
    "### 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-wilderness",
   "metadata": {},
   "source": [
    "학습된 FastText 모형을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "commercial-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "ft = FastText.load('../data/nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-valve",
   "metadata": {},
   "source": [
    "데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "brazilian-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nsmc = pd.read_csv('../data/ratings_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-jimmy",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-vertex",
   "metadata": {},
   "source": [
    "리뷰가 있는 데이터만 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "banner-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nsmc[nsmc['document'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-cloud",
   "metadata": {},
   "source": [
    "훈련용 데이터와 테스트용 데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fluid-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "injured-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_train, doc_test, y_train, y_test = train_test_split(df['document'], df['label'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-antique",
   "metadata": {},
   "source": [
    "한글 단어만 추출하는 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "flush-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_hangul(text):\n",
    "    return re.findall(r'[ㄱ-ㅎ가-힣]+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-pottery",
   "metadata": {},
   "source": [
    "1000, 16 크기의 행렬을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "detected-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.zeros((1000, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-claim",
   "metadata": {},
   "source": [
    "각 문서에서 한글 단어를 찾아 단어 임베딩을 구하고, 이를 문서마다 평균을 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hundred-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(doc_train.iloc[:1000]):\n",
    "    vs = [ft.wv[word] for word in find_hangul(doc)]\n",
    "    if vs:\n",
    "        x_train[i,] = np.mean(vs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-table",
   "metadata": {},
   "source": [
    "x_train은 각 문서의 단어 임베딩 평균이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "expressed-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46497652,  1.30914772,  2.05310345,  0.70937788, -0.22061728,\n",
       "        0.12521037, -0.55661809, -0.49261209,  0.84338641, -0.91445994,\n",
       "       -1.5739845 , -0.66046977,  0.17000785, -0.60663056, -0.24857529,\n",
       "       -0.97864735])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-minimum",
   "metadata": {},
   "source": [
    "# 모형 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-session",
   "metadata": {},
   "source": [
    "각 문서의 단어 임베딩 평균을 이용하여 감성을 예측하는 모형을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "single-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "likely-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "backed-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bibliographic-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8647 - accuracy: 0.4380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e10e415b20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train.values[:1000], epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-navigation",
   "metadata": {},
   "source": [
    "# 순환신경망 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-class",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "latin-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/imdb.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eleven-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "tk = joblib.load('../data/tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-armor",
   "metadata": {},
   "source": [
    "데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adapted-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "first-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train, review_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-network",
   "metadata": {},
   "source": [
    "토큰화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "threatened-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = tk.texts_to_sequences(review_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-mainland",
   "metadata": {},
   "source": [
    "### 순방향 순환신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cellular-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-complexity",
   "metadata": {},
   "source": [
    "패딩을 한다. 길이가 짧으면 앞쪽에 0을 채운다(padding='pre'). maxlen은 최대 길이를 지정할 수 있다. 지정하지 않으면 가장 긴 문자열의 길이로 지정된다. truncating='pre'는 maxlen보다 긴 문자열일 경우 앞쪽을 자른다. 뒤쪽을 자르게 하려면 'post'로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adjustable-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = tf.keras.preprocessing.sequence.pad_sequences(seqs, maxlen=None, padding='pre', truncating='pre')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "manufactured-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS= tk.num_words + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-liberia",
   "metadata": {},
   "source": [
    "Embedding에서 mask_zero=True로 설정하면 0으로 패딩된 부분의 예측은 손실에 반영하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "loving-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(8),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "framed-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 8)           16008     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 16,561\n",
      "Trainable params: 16,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-tobacco",
   "metadata": {},
   "source": [
    "모형을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "retained-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "visible-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 2s 15ms/step - loss: 0.6932 - accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6911 - accuracy: 0.6438\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.6865 - accuracy: 0.7050\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6733 - accuracy: 0.8338\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6213 - accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.5146 - accuracy: 0.8637\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4312 - accuracy: 0.8913\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3727 - accuracy: 0.9162\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.3169 - accuracy: 0.9425\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.2830 - accuracy: 0.9425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e10e3a4e80>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pads, y_train.values, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-switch",
   "metadata": {},
   "source": [
    "### 역방향 순환신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-contamination",
   "metadata": {},
   "source": [
    "패딩을 한다. 길이가 짧으면 뒤쪽에 0을 채운다(padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pharmaceutical-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = tf.keras.preprocessing.sequence.pad_sequences(seqs, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "nasty-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(8, go_backwards=True),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-method",
   "metadata": {},
   "source": [
    "### 양방향 순환신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-stylus",
   "metadata": {},
   "source": [
    "LSTM을 Bidirectional로 감싸주면 자동으로 순방향과 역방향 레이어를 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "handy-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "worst-horizontal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 8)           16008     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 16)                1088      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 17,113\n",
      "Trainable params: 17,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8_DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
