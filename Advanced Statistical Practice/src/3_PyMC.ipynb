{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = navy>3.  PyMC3 </font>\n",
    "    \n",
    "Pythonì˜ PyMC3 ëª¨ë“ˆì˜ ì‚¬ìš©ë²•ì„ ì†Œê°œí•˜ê³  ëª¨ë¸ë§ í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model creation\n",
    "\n",
    "- PyMC3ì—ì„œëŠ” ëª¨ë¸ì— í¬í•¨í•˜ê³  ì‹¶ì€ ëª¨ë“  ë³€ìˆ˜ë“¤ì„ ê¸°ë³¸ì ìœ¼ë¡œ `Model` object ì•ˆì—ì„œ ì •ì˜í•œë‹¤. `Model`ì•ˆì—ì„œ ì •ì˜ëœ ë³€ìˆ˜ëŠ” ê·¸ ëª¨ë¸ë¡œ í• ë‹¹ëœë‹¤. \n",
    "- ê° ë³€ìˆ˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì •ì˜í•œë‹¤. `pm.Exponential`ì™€ `pm.Poisson`ì˜ ì²« ë²ˆì§¸ argumentëŠ” ë³€ìˆ˜ ì´ë¦„, ë‘ ë²ˆì§¸ argumentëŠ” í•´ë‹¹ ë¶„í¬ì˜ ëª¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\lambda \\sim Exponential(1)$$\n",
    "$$ X |\\lambda\\sim Poisson(\\lambda)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    parameter = pm.Exponential(\"poisson_param\", 1.0)\n",
    "    data_generator = pm.Poisson(\"data_generator\", parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `with`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì—ì„œ ì§€ì •í•œ ëª¨ë¸ì— ëŒ€í•œ ì‘ì—…ì„ ê³„ì†í•  ìˆ˜ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    data_plus_one = data_generator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\text{poisson_param} \\sim \\text{Exponential}(\\mathit{lam}=1.0)$"
      ],
      "text/plain": [
       "poisson_param ~ Exponential"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\text{data_generator} \\sim \\text{Poisson}(\\mathit{mu}=\\text{poisson_param})$"
      ],
      "text/plain": [
       "data_generator ~ Poisson"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{add,no_inplace}.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_plus_one \n",
    "# ì•„ì§ì€ ìƒ˜í”Œë§í•˜ì§€ ì•Šì•˜ì§€ë§Œ ê°ê°ì˜ elementì— ëŒ€í•´ì„œ 1ì„ ë”í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pymc3 continuous distributions\n",
    "https://docs.pymc.io/api/distributions/continuous.html\n",
    "- Pymc3 discrete distributions\n",
    "https://docs.pymc.io/api/distributions/discrete.html?highlight=discrete#module-pymc3.distributions.discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 PyMC3 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ëª¨ë“  PyMC3 variableì€ initial valueë¥¼ ê°€ì§€ê³  ìˆë‹¤.\n",
    "    - `ë³€ìˆ˜ëª….tag.test_value`ë¡œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter.tag.test_value = 0.6931471824645996\n",
      "data_generator.tag.test_value = 0\n",
      "data_plus_one.tag.test_value = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"parameter.tag.test_value =\", parameter.tag.test_value)\n",
    "print(\"data_generator.tag.test_value =\", data_generator.tag.test_value)\n",
    "print(\"data_plus_one.tag.test_value =\", data_plus_one.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `testval` ì˜µì…˜ìœ¼ë¡œ initial value ì§€ì • ê°€ëŠ¥ \n",
    "- initial valueëŠ” í•´ë‹¹ ëª¨ìˆ˜ì˜ samplingì˜ ì´ˆê¸°ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parameter.tag.test_value = 0.5\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    parameter = pm.Exponential(\"poisson_param\", 1.0, testval=0.5)\n",
    "\n",
    "print(\"\\nparameter.tag.test_value =\", parameter.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic vs Deterministic Variable\n",
    "- **Stochastic variable**: ê³ ì •ë˜ì–´ ìˆì§€ ì•Šì€ í™•ë¥ ë³€ìˆ˜(random variable). ì£¼ì–´ì§„ ëª¨ìˆ˜ ê°’ì„ ê°€ì§„ ë¶„í¬ì—ì„œ í™•ë¥ ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ë³€ìˆ˜. `Poisson`, `DiscreteUniform`, `Normal`, `Exponential` ë“±ì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ë‹¤. \n",
    "    - $X \\sim N(\\mu, \\sigma^2)$\n",
    "        - $\\mu=0, \\sigma=1$ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤ê³  í•´ë„ Xê°’ì€ ê³ ì •ë˜ì§€ ì•ŠëŠ”ë‹¤. ë‹¨ 0ê³¼ ê°€ê¹Œìš´ ê°’ì„ ê°€ì§ˆ í™•ë¥ ì´ ë†’ì„ ë¿..\n",
    "\n",
    "- **Deterministic variable**: ê³ ì •ë˜ì–´ ìˆëŠ” ìƒìˆ˜. ë‹¤ë¥¸ ë³€ìˆ˜ì˜ í•¨ìˆ˜ë¡œ í‘œí˜„ë˜ë”ë¼ë„ ì¸ìˆ˜ê°’ì´ ì£¼ì–´ì§„ë‹¤ë©´ ë³€ìˆ˜ ê°’ë„ ì–¸ì œê°€ ê³ ì •ë˜ëŠ” ë³€ìˆ˜\n",
    "    - $X=a+2$\n",
    "        - $a=1$ë¡œ ì£¼ì–´ì§€ë©´ $X$ëŠ” 3ìœ¼ë¡œ ê³ ì •ëœë‹¤. $a$ê°€ ë³€í•˜ë©´ $X$ê°€ ë³€í•˜ê¸´ í•˜ì§€ë§Œ í™•ë¥ ì ìœ¼ë¡œ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
    "    - $Y=X+2, X\\sim N(0,1)$\n",
    "        - $X$ê°€ í™•ë¥ ë³€ìˆ˜ì´ê¸° ë•Œë¬¸ì— $Y$ ì—­ì‹œ (í†µê³„ì´ë¡ ì ìœ¼ë¡œëŠ”) í™•ë¥ ë³€ìˆ˜ì´ì§€ë§Œ, PyMC3 í™˜ê²½ì—ì„œëŠ” Xê°€ ì£¼ì–´ì§„ ìˆ˜ë¼ë©´ Yê°€ ìƒìˆ˜ì´ë¯€ë¡œ deterministic variableë¡œ ì—¬ê¸´ë‹¤.\n",
    "\n",
    "#### Initializing Stochastic variables\n",
    "\n",
    "Stochastic variableì„ ì´ˆê¸°í™”í•˜ê¸° ìœ„í•´ì„œëŠ” `name` argumentì™€ í•´ë‹¹ ë¶„í¬ í´ë˜ìŠ¤ì˜ ëª¨ìˆ˜ë¥¼ ì…ë ¥í•´ì•¼ í•œë‹¤. \n",
    "\n",
    "`some_variable = pm.DiscreteUniform(\"discrete_uni_var\", 0, 4)`\n",
    "\n",
    "- 0, 4: `DiscreteUniform`ë¶„í¬ì˜ ë²”ìœ„\n",
    "- `discrete_uni_var`: ë³€ìˆ˜ì˜ ì´ë¦„. ì´í›„ ë¶„ì„ì—ì„œ ì‚¬í›„ë¶„í¬ë¥¼ ì¶”ì í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.\n",
    "\n",
    "ë‹¤ë³€ëŸ‰ ë¬¸ì œì—ì„œëŠ” `shape` keywordë¥¼ ì‚¬ìš©í•˜ì—¬ ë…ë¦½ì ì¸ stochastic variablesì„ ìƒì„±í•œë‹¤.  NumPy arrayì™€ ê°™ì´ ì‘ë™í•œë‹¤.\n",
    "ë³€ìˆ˜ì˜ `tag.test_value` attributeì€ ì´ˆê¸°ê°’ì„ NumPy arraysë¡œ ì¶œë ¥í•œë‹¤. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í•˜ë‚˜ì”© ë”°ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    beta_1 = pm.Uniform(\"beta_1\", 0, 1)\n",
    "    beta_2 = pm.Uniform(\"beta_2\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1.tag.test_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_2.tag.test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "ìœ„ì²˜ëŸ¼ ë”°ë¡œ ìƒì„±í•˜ëŠ” ëŒ€ì‹  ì•„ë˜ì²˜ëŸ¼ í•œë²ˆì— ë‹¤ë³€ëŸ‰ stochastic variableì„ ìƒì„± ê°€ëŠ¥\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    betas = pm.Uniform(\"betas\", 0, 1, shape=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.tag.test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic variables\n",
    "\n",
    "PyMC3ì˜ `Deterministic` classë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì˜ëœë‹¤. \n",
    "\n",
    "    deterministic_variable = pm.Deterministic(\"deterministic variable\", some_function_of_variables)\n",
    "\n",
    "`pymc3.Deterministic`ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ (í™•ë¥ )ë³€ìˆ˜ì˜ ì‚¬ì¹™ì—°ì‚°ì´ë‚˜ exponentials, log ë“±ì˜ í•¨ìˆ˜ í˜•íƒœë¡œ ì •ì˜í•  ìˆ˜ë„ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", 1.0)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", 1.0)\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=10)\n",
    "    new_deterministic_variable = lambda_1 + lambda_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943649291992"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_1.tag.test_value + lambda_2.tag.test_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.38629436)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_deterministic_variable.tag.test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic variableì„ samplingê³¼ì •ì—ì„œ ì¶”ì í•˜ê¸° ìœ„í•´ì„œëŠ” `model` context ì•ˆì—ì„œ ì •ì˜í•´ì•¼ í•œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", 1.0)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", 1.0)\n",
    "\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=10)\n",
    "    new_deterministic_variable = pm.Deterministic('lambda_sum', lambda_1 + lambda_2) # Deterministic Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.38629436)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_deterministic_variable.tag.test_value \n",
    "# lambda_sum ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ new_deterministic_variable ê°’ë“¤ 10000ê°œê°€ ì €ì¥\n",
    "# -> ë‚˜ì¤‘ì— ê·¸ ê°’ë“¤ì„ trackingí•´ì„œ ì‚¬ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¬¸ìë©”ì„¸ì§€ ì˜ˆì œì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ì€ ì•„ë˜ì™€ ê°™ë‹¤. \n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_data_points = 5  # ì´ì „ ì˜ˆì œì—ì„œëŠ” 70ê°œ ì •ë„ì˜ ë°ì´í„°ê°€ ìˆì—ˆìŒ\n",
    "idx = np.arange(n_data_points) # ì‹œì  ì¸ë±ìŠ¤ \n",
    "with model:\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2) #ì‹œì ì´ tauë³´ë‹¤ ì‘ìœ¼ë©´ lambda_1, í¬ê±°ë‚˜ ê°™ìœ¼ë©´ lambda_2\n",
    "    # ë³´í†µ ê´€ì‹¬ì´ ì—†ëŠ” ë³€ìˆ˜ ë’¤ì— _(ì–¸ë”ë°”)ë¥¼ ë¶™ì„. ë‹¤ë¥¸ ë³€ìˆ˜ì— ë„£ì–´ ì“°ê¸° ìœ„í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ì— ê´€ì¸¡ì¹˜ í¬í•¨í•˜ê¸°\n",
    "\n",
    "ìœ„ì˜ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì˜ ì‚¬ì „ë¶„í¬ë¥¼ ì •ì˜í–ˆë‹¤. $\\lambda_1$ì˜ ì‚¬ì „ë¶„í¬ê°€ ì–´ë–»ê²Œ ìƒê²¼ì„ê¹Œ? ì•„ë˜ì˜ ë‘ê°€ì§€ ë°©ë²•\n",
    "1. ìœ„ì—ì„œ ì •ì˜ëœ Exponential ë¶„í¬ì˜ ëª¨ì–‘ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì•Œì•„ë³¸ë‹¤.\n",
    "    - ë§Œì¼ ìš°ë¦¬ê°€ ê´€ì‹¬ìˆëŠ” ë¶„í¬ê°€ Exponential ê°™ì´ ì˜ ì•Œë ¤ì§„ ë¶„í¬ê°€ ì•„ë‹ˆë©´ ì´ ë°©ë²•ì€ ì“¸ ìˆ˜ ì—†ë‹¤ (ì˜ˆë¥¼ ë“¤ë©´, $\\lambda$ì˜ ë¶„í¬)\n",
    "- í•´ë‹¹ ë¶„í¬ì—ì„œ random sampleì„ ì¶”ì¶œí•˜ì—¬ ì´ê²ƒì˜ íˆìŠ¤í† ê·¸ë¨ì„ ê·¸ë ¤ì„œ ì•Œì•„ë³¸ë‹¤.\n",
    "    - ë³µì¡í•œ ë¶„í¬ì—ì„œë„ MCMCë¥¼ ì‚¬ìš©í•˜ì—¬ random sampleì„ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤. \n",
    "    - ì£¼ë¡œ ì´ ë°©ë²•ì„ ì‚¬ìš© \n",
    "\n",
    "**NOTE**\n",
    "- ì—¬ê¸°ì„œ ì¶”ì¶œí•œ sampleì€ ê´€ì¸¡ì¹˜ê°€ ì•„ë‹ˆë¼ ê´€ì‹¬ ëª¨ìˆ˜ì˜ ì‹¤í˜„ì¹˜\n",
    "- (Frequentist ì²˜ëŸ¼) ëª¨ìˆ˜ì˜ ê°’ì„ í•˜ë‚˜ì˜ ê°’ í˜¹ì€ êµ¬ê°„ìœ¼ë¡œ ì¶”ì •í•˜ê¸° ë³´ë‹¤ëŠ” ëª¨ìˆ˜ì˜ ë¶„í¬ë¥¼ ê°€ì •í•˜ê³  ê±°ê¸°ì„œ random sampleì„ ì¶”ì¶œí•˜ì—¬ ê·¸ê²ƒì˜ ë¶„í¬, í‰ê· , ë¶„ì‚° ë“±ìœ¼ë¡œ ëª¨ìˆ˜ì— ëŒ€í•´ ì¶”ë¡ í•˜ë ¤ëŠ” ëª©ì  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ë¶„í¬ì—ì„œ random sampleì„ 20000ê°œ ì¶”ì¶œ -> ë¶„í¬ë¥¼ ì‹œê°í™”, lambdaë¼ëŠ” ëª¨ìˆ˜ì˜ ì‹¤í˜„ì¹˜ ìƒ˜í”Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "figsize(12.5, 4)\n",
    "\n",
    "samples = lambda_1.random(size=20000)\n",
    "plt.hist(samples, bins=70, density=True, histtype=\"stepfilled\")\n",
    "plt.title(\"Prior distribution for $\\lambda_1$\")\n",
    "plt.xlim(0, 8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: ê·¸ë ‡ë‹¤ë©´ ê´€ì¸¡ì¹˜ë¥¼ ì–´ë–»ê²Œ ëª¨í˜•ì— ë°˜ì˜ì‹œí‚¬ê¹Œ?  \n",
    "\n",
    "- Stochastic variableì˜  `observed` argumentë¥¼ ì‚¬ìš©\n",
    "- í•´ë‹¹ ë³€ìˆ˜ì˜ ê°’ì„ ì£¼ì–´ì§„ ë°ì´í„°ë¡œ ê³ ì •ì‹œí‚¤ëŠ” ì—­í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 15 20 35]\n"
     ]
    }
   ],
   "source": [
    "# We're using some fake data here\n",
    "data = np.array([10, 25, 15, 20, 35])\n",
    "with model:\n",
    "    obs = pm.Poisson(\"obs\", lambda_, observed=data)\n",
    "print(obs.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 ëª¨ë¸ë§ ë°©ë²•\n",
    "\n",
    "- ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë§Œë“¤ì–´ ì¡ŒëŠ”ì§€ì— ëŒ€í•œ ê³¼ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìƒê°\n",
    "- ë‚´ê°€ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë§Œë“ ë‹¤ë©´ ì–´ë–¤ ê³¼ì •ìœ¼ë¡œ ë§Œë“¤ ê²ƒì¸ê°€? \n",
    "\n",
    "### ë¬¸ìë©”ì„¸ì§€ ì˜ˆì œ\n",
    "\n",
    "1.  \"count data\"ê°€ ì¶”ì¶œë  ìˆ˜ ìˆëŠ” í™•ë¥ ë¶„í¬ëŠ” ë¬´ì—‡ì¸ê°€? \n",
    "    -  Poisson ë¶„í¬ê°€ ì¢‹ì€ í›„ë³´ì„\n",
    "    - $C_i \\sim Poi(\\lambda)$\n",
    "\n",
    "\n",
    "2.  í¬ì•„ì†¡ ë¶„í¬ì˜ ëª¨ìˆ˜ì¸ $\\lambda$ë¥¼ ì•Œê³  ìˆëŠ”ê°€? \n",
    "    - ëª¨ë¥¼ ë¿ ì•„ë‹ˆë¼ ë³€í™˜ì ($\\tau$) ì´í›„ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ê°€ì •\n",
    "    $$\\lambda = \\left\\{\n",
    "\\begin{matrix}\n",
    "\\lambda_1 & \\mbox{if } t<\\tau\\\\\n",
    "\\lambda_2 & \\mbox{if } t\\geq\\tau\\\\\n",
    "\\end{matrix}\n",
    "\\right. $$ \n",
    "\n",
    "3. ë‘ ê°œì˜  $\\lambda$ì— ëŒ€í•œ ì ì ˆí•œ í™•ë¥ ë¶„í¬ëŠ” ë¬´ì—‡ì¸ê°€?\n",
    "    - $\\lambda$ëŠ” í‰ê·  countì˜ ì˜ë¯¸ë¥¼ ê°€ì§€ë¯€ë¡œ ì–‘ì˜ ê°’ì— ëŒ€í•´ ì •ì˜ë˜ëŠ” ë¶„í¬ì´ì–´ì•¼ í•¨\n",
    "    - ì§€ìˆ˜ë¶„í¬ê°€ ì¢‹ì€ í›„ë³´ \n",
    "    - $\\lambda_j\\sim Exponential(\\alpha)$ \n",
    "    \n",
    "\n",
    "4.  ì§€ìˆ˜ë¶„í¬ì˜ ëª¨ìˆ˜ì¸ $\\alpha$ë¥¼ ì•„ëŠ”ê°€? \n",
    "    - ëª¨ë¦„. $\\alpha$ì— ëŒ€í•´ ë˜ë‹¤ì‹œ í™•ë¥ ë¶„í¬ë¥¼ ì ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ ê·¸ë§Œí¼ ê´€ì‹¬ì´ ìˆì§€ ì•Šê³  ì‚¬ì „ ì •ë³´ê°€ ë³„ë¡œ ì—†ìŒ \n",
    "    - $\\lambda$ì— ëŒ€í•œ ì‚¬ì „ ì •ë³´(10-30 ì‚¬ì´ì˜ ê°’?)ë¥¼ $\\alpha$ê°€ ì˜ ë°˜ì˜í•˜ê²Œ í•˜ê¸° ìœ„í•´ $\\lambda|\\alpha$ì˜ ê¸°ëŒ€ê°’ì´ ê´€ì¸¡ì¹˜ì˜ í‰ê· ì´ ë˜ë„ë¡ ì„¤ì •í•¨\n",
    "$$\\frac{1}{N}\\sum_{i=0}^N \\;C_i \\approx E[\\; \\lambda \\; |\\; \\alpha ] = \\frac{1}{\\alpha}$$ \n",
    "\n",
    "\n",
    "5. ì „í™˜ì  $\\tau$ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ì „ì²´ ì¼ìì— ëŒ€í•œ ê· ë“± ë¶„í¬ë¡œ ì‚¬ì „ë¶„í¬ë¥¼ ì„¤ì • \n",
    "\\begin{align}\n",
    "& \\tau \\sim \\text{DiscreteUniform(1,70) }\\\\\\\\\n",
    "& \\Rightarrow P( \\tau = k ) = \\frac{1}{70}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "ëª¨í˜•ì—ì„œ ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.\n",
    "<img src=\"http://i.imgur.com/7J30oCG.png\" width = 700/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## DO NOT RUN \\nwith pm.Model() as model:\\n    alpha = 1.0/count_data.mean()  # Recall count_data is the\\n                                   # variable that holds our txt counts\\n    lambda_1 = pm.Exponential(\"lambda_1\", alpha)\\n    lambda_2 = pm.Exponential(\"lambda_2\", alpha)\\n    \\n    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count_data - 1)\\n\\n    idx = np.arange(n_count_data) # Index\\n    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\\n    \\n    observation = pm.Poisson(\"obs\", lambda_, observed=count_data)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## DO NOT RUN \n",
    "with pm.Model() as model:\n",
    "    alpha = 1.0/count_data.mean()  # Recall count_data is the\n",
    "                                   # variable that holds our txt counts\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", alpha)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", alpha)\n",
    "    \n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count_data - 1)\n",
    "\n",
    "    idx = np.arange(n_count_data) # Index\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "    \n",
    "    observation = pm.Poisson(\"obs\", lambda_, observed=count_data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "   ## ëª¨í˜• êµ¬ì„±\n",
    "    theta = pm.Beta('theta', alpha, beta)\n",
    "    obs = pm.Binomial('obs', n, theta, observed `= y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-370889a8f0a9>:3: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(10000, tune=5000,step=step, chains=1)\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "Metropolis: [theta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15000' class='' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15000/15000 00:31<00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 5_000 tune and 10_000 draw iterations (5_000 + 10_000 draws total) took 32 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(10000, tune=5000,step=step, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31536456720801587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ì‚¬í›„ë¶„í¬ì˜ í‰ê· ì„ MCMC ìƒ˜í”Œë¡œë¶€í„° ê³„ì‚° \n",
    "theta_samples = trace['theta']\n",
    "theta_samples.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example: ìŠ¤í¬ì¸  ê²½ê¸° (ì´í•­ë¶„í¬-ë² íƒ€ë¶„í¬)\n",
    "ìŠ¤í¬ì¸  ê²½ê¸°ì—ì„œ AíŒ€ì´ BíŒ€ê³¼ 12ë²ˆì˜ ê²½ê¸°ë¥¼ ìˆ˜í–‰í•˜ì—¬ 3ë²ˆì˜ ìŠ¹ë¦¬ë¥¼ ê±°ë‘ì—ˆë‹¤. ì´ì— ëŒ€í•œ ì´í•­ë¶„í¬ì˜ ëª¨ìˆ˜ë¥¼ Beta(2,2) ì‚¬ì „ë¶„í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë² ì´ì§€ì•ˆ ì¶”ë¡ ìœ¼ë¡œ ì¶”ì •í•˜ê¸° ìœ„í•œ ëª¨í˜•ì„ êµ¬ì„±í•˜ë¼. MCMC ë°©ë²•ì„ í†µí•´ ì‚¬í›„ë¶„í¬ì—ì„œ ì¶”ì¶œí•œ ì´í•­ë¶„í¬ ëª¨ìˆ˜ì˜ í‰ê· ì„ êµ¬í•˜ì‹œì˜¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "   ## ëª¨í˜• êµ¬ì„±\n",
    "    theta = pm.Beta('theta', 2, 2)\n",
    "    obs = pm.Binomial('obs', 12, theta, observed `= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-370889a8f0a9>:3: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(10000, tune=5000,step=step, chains=1)\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "Metropolis: [theta]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15000' class='' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15000/15000 00:31<00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 5_000 tune and 10_000 draw iterations (5_000 + 10_000 draws total) took 32 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(10000, tune=5000,step=step, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31536456720801587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ì‚¬í›„ë¶„í¬ì˜ í‰ê· ì„ MCMC ìƒ˜í”Œë¡œë¶€í„° ê³„ì‚° \n",
    "theta_samples = trace['theta']\n",
    "theta_samples.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ì˜ Beta-binomial ëª¨í˜•ì˜ ì‚¬í›„ë¶„í¬ì™€ $Beta(\\alpha, \\beta)$ì˜ í‰ê· ì´ $\\alpha/(\\alpha+\\beta)$ë¼ëŠ” ì‚¬ì‹¤ì„ ì´ìš©í•˜ì—¬ ìœ„ì—ì„œ ê³„ì‚°í•œ ì‚¬í›„í‰ê· ì´ ì ì ˆí•œì§€ íŒë‹¨í•˜ì‹œì˜¤. \n",
    "$$ \\theta \\sim Beta(\\alpha, \\beta)$$ \n",
    "$$ y|\\theta \\sim Bin(n, \\theta)$$ \n",
    "$$ \\theta|y \\sim Beta(\\alpha+y, \\beta+n-y)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì‚¬í›„ë¶„í¬ì˜ í‰ê· ì„ Beta ë¶„í¬ì˜ í‰ê·  ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° \n",
    "\n",
    "alpha = 2\n",
    "beta = 2\n",
    "n = 12\n",
    "y = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ğœƒ|ğ‘¦ \\sim ğµğ‘’ğ‘¡ğ‘(ğ›¼+ğ‘¦,ğ›½+ğ‘›âˆ’ğ‘¦) = ğµğ‘’ğ‘¡ğ‘(5,11)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# posterior = Beta(2+3, 2+12-3) = Beta(5,11)\n",
    "posterior_mean = (alpha+y)/((beta+n-y)+(alpha+y)) # 5/16\n",
    "posterior_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: ì •ê·œë¶„í¬ \n",
    "ì–´ëŠ ì œí’ˆ ì¤‘ëŸ‰ì´ í‰ê·  100, í‘œì¤€í¸ì°¨ 2 ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ì•Œë ¤ì ¸ ìˆë‹¤. 5ê°œ ì œí’ˆ ì¡°ì‚¬ê²°ê³¼ 98, 100, 101, 102, 103ì´ì—ˆë‹¤. ì œí’ˆì˜ ì¤‘ëŸ‰ í‰ê·  ì¶”ì •ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ê¸° ìœ„í•œ ë² ì´ì§€ì•ˆ ëª¨í˜•ì„ êµ¬ì„±í•˜ë¼. (í‘œì¤€í¸ì°¨=2 ê°€ì •) \n",
    "$$ \\mu \\sim N(100, 2^2)$$ \n",
    "$$ X|\\mu \\sim N(\\mu, 2^2)$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    ## ëª¨í˜• êµ¬ì„± \n",
    "    mu = pm.Normal('mu', mu=100, sigma = 2)\n",
    "    obs = pm.Normal('obs', mu, observed = [98, 100, 101, 102, 103])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-370889a8f0a9>:3: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(10000, tune=5000,step=step, chains=1)\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "Metropolis: [mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15000' class='' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15000/15000 00:44<00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 5_000 tune and 10_000 draw iterations (5_000 + 10_000 draws total) took 45 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(10000, tune=5000,step=step, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.76290896207986"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ì‚¬í›„ë¶„í¬ì˜ í‰ê·  ê³„ì‚° \n",
    "trace['mu'].mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8_DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
