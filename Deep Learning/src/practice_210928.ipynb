{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e151564",
   "metadata": {},
   "source": [
    "## 210928 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6f8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8500, 0.4800]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1910]], grad_fn=<MmBackward>)\n",
      "Iteration:  0 \t Loss:  0.327240526676178\n",
      "tensor([[0.1100, 0.2100],\n",
      "        [0.1200, 0.0800]], requires_grad=True)\n",
      "tensor([[0.1400],\n",
      "        [0.1500]], requires_grad=True)\n",
      "y_pred:  tensor([[0.1910]], grad_fn=<MmBackward>)\n",
      "1 step loss:  tensor(0.3272, grad_fn=<SumBackward0>)\n",
      "tensor([[0.9236, 0.5589]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2557]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1213, 0.2270],\n",
      "        [0.1321, 0.0982]], requires_grad=True)\n",
      "tensor([[0.1744],\n",
      "        [0.1694]], requires_grad=True)\n",
      "y_pred:  tensor([[0.2557]], grad_fn=<MmBackward>)\n",
      "2 step loss:  tensor(0.2770, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available(): # 현재 파이썬이 실행되고 있는 환경에서 torch 모듈을 이용할 때 GPU를 이용할 수 있는지 확인하는 함수\n",
    "    DEVICE = torch.device('cuda') # 참이면 'cuda' 이용\n",
    "else:\n",
    "    DEVICE = torch.device('cpu') # 거짓이면 'cpu' 이용\n",
    "\n",
    "x = torch.tensor([[2.0, 3.0]], requires_grad=False)\n",
    "y = torch.tensor([[1.0]], requires_grad=False)\n",
    "\n",
    "w1 = torch.tensor([[0.11, 0.21],\n",
    "                   [0.12, 0.08]], requires_grad=True)\n",
    "w2 = torch.tensor([[0.14],\n",
    "                   [0.15]], requires_grad=True)\n",
    "\n",
    "# 학습 정도를 결정하는 learning_rate 설정\n",
    "learning_rate = 0.05                                         \n",
    "for t in range(2):\n",
    "    hidden = x @ w1 #.T\n",
    "    print(hidden)\n",
    "    y_pred = hidden @ w2\n",
    "    print(y_pred)\n",
    "    \n",
    "    loss = torch.sum(((y_pred - y).pow(2))*(1/2))\n",
    "    if t % 100 == 0:\n",
    "        print(\"Iteration: \", t, \"\\t\", \"Loss: \", loss.item()) # loss.item(): tensor type을 Python number type으로 바꿔줌\n",
    "    print(w1)\n",
    "    print(w2)\n",
    "    print('y_pred: ', y_pred)\n",
    "    print(str(t+1)+\" step loss: \", loss)\n",
    "    \n",
    "    if t == 0:\n",
    "        loss.backward()\n",
    "        with torch.no_grad(): # 아래 코드들은 Gradient를 추가 계산하지 않고 고정시킨 상태에서 실행됨                                     \n",
    "            w1 -= learning_rate * w1.grad # w1 Update\n",
    "            w2 -= learning_rate * w2.grad # w2 Update              \n",
    "\n",
    "            w1.grad.zero_() # w1에 저장되어 있는 Gradient를 0으로 초기화             \n",
    "            w2.grad.zero_() # w2에 저장되어 있는 Gradient를 0으로 초기화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8_DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
